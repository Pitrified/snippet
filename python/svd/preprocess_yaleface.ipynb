{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract faces from images\n",
    "\n",
    "Preprocess the \n",
    "[Yale face dataset](https://www.kaggle.com/datasets/olgabelitskaya/yale-face-database/code?resource=download)\n",
    "to obtain images where the face is centered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "from loguru import logger as lg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_face(\n",
    "    img_path: Path,\n",
    "    haar_cascade: cv2.CascadeClassifier,\n",
    "    w_crop: int,\n",
    "    h_crop: int,\n",
    "    data_crop_fol: Path,\n",
    ") -> int:\n",
    "    \"\"\"Crop the face from the image and save it as a png file.\n",
    "\n",
    "    If no face is found, the image is not saved.\n",
    "    If more than one face is found, the first one is used.\n",
    "\n",
    "    Args:\n",
    "        img_path (Path): Path to the image.\n",
    "        haar_cascade (cv2.CascadeClassifier): Haar cascade classifier.\n",
    "        w_crop (int): Width of the cropped image.\n",
    "        h_crop (int): Height of the cropped image.\n",
    "        data_crop_fol (Path): Path to the folder where the cropped images will be saved.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of faces found in the image.\n",
    "    \"\"\"\n",
    "    # load the image as ndarray[float64, float64]\n",
    "    pix = plt.imread(str(img_path))\n",
    "\n",
    "    # convert it to grayscale for opencv\n",
    "    im = np.array(pix, dtype=np.uint8)\n",
    "\n",
    "    # detect faces in the image\n",
    "    faces = haar_cascade.detectMultiScale(\n",
    "        im,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE,\n",
    "    )\n",
    "\n",
    "    # sanity check\n",
    "    if len(faces) == 0:\n",
    "        lg.warning(f\"No faces found in {img_path}\")\n",
    "        return 0\n",
    "    if len(faces) > 1:\n",
    "        lg.warning(f\"{len(faces)} found in {img_path}\")\n",
    "\n",
    "    # get the corner and the size of the face\n",
    "    x, y, w, h = faces[0]\n",
    "\n",
    "    # crop the image\n",
    "    im_crop = crop_face_within_bounds(im, w_crop, h_crop, x, y, w, h)\n",
    "\n",
    "    # save the image as a png file\n",
    "    img_path_crop = data_crop_fol / f\"{img_path.name}.png\"\n",
    "    cv2.imwrite(str(img_path_crop), im_crop)\n",
    "\n",
    "    return len(faces)\n",
    "\n",
    "\n",
    "def crop_face_within_bounds(\n",
    "    im: npt.NDArray[np.uint8],\n",
    "    w_crop: int,\n",
    "    h_crop: int,\n",
    "    x: int,\n",
    "    y: int,\n",
    "    w: int,\n",
    "    h: int,\n",
    "):\n",
    "    \"\"\"Crop the image within the bounds of the original image.\n",
    "\n",
    "    Args:\n",
    "        im (npt.NDArray[np.uint8]): Image to crop.\n",
    "        w_crop (int): Width of the cropped image.\n",
    "        h_crop (int): Height of the cropped image.\n",
    "        x (int): X coordinate of the top left corner of the face.\n",
    "        y (int): Y coordinate of the top left corner of the face.\n",
    "        w (int): Width of the face.\n",
    "        h (int): Height of the face.\n",
    "\n",
    "    Returns:\n",
    "        npt.NDArray[np.uint8]: Cropped image.\n",
    "    \"\"\"\n",
    "    # compute the center\n",
    "    x_center = x + w // 2\n",
    "    y_center = y + h // 2\n",
    "\n",
    "    # compute the bbox\n",
    "    x_left = x_center - w_crop // 2\n",
    "    x_right = x_center + w_crop // 2\n",
    "    y_top = y_center + h_crop // 2\n",
    "    y_bottom = y_center - h_crop // 2\n",
    "\n",
    "    # get the original dimensions\n",
    "    h_orig, w_orig = im.shape\n",
    "\n",
    "    # fix the bbox outside the image\n",
    "    if x_left < 0:\n",
    "        x_left = 0\n",
    "        x_right = w_crop\n",
    "    if x_right >= w_orig:\n",
    "        x_left = w_orig - w_crop\n",
    "        x_right = w_orig\n",
    "    if y_bottom < 0:\n",
    "        y_bottom = 0\n",
    "        y_top = h_crop\n",
    "    if y_top >= h_orig:\n",
    "        y_bottom = h_orig - h_crop\n",
    "        y_top = h_orig\n",
    "\n",
    "    # crop the image\n",
    "    im_crop = im[y_bottom:y_top, x_left:x_right]\n",
    "    return im_crop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_fol = Path(\"~/data/yaleface/data\").expanduser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the haar algorithm file\n",
    "alg = \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "# pass the algorithm to OpenCV\n",
    "haar_cascade: cv2.CascadeClassifier = cv2.CascadeClassifier(alg)\n",
    "\n",
    "# create the output folder\n",
    "data_crop_fol = data_root_fol.parent / \"data_crop_tes\"\n",
    "if not data_crop_fol.exists():\n",
    "    data_crop_fol.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Saving cropped images in {data_crop_fol}\")\n",
    "\n",
    "w_crop = 160\n",
    "h_crop = 180\n",
    "\n",
    "for img_path in data_root_fol.iterdir():\n",
    "    crop_face(img_path, haar_cascade, w_crop, h_crop, data_crop_fol)\n",
    "    # break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56fddae659bb42062d07dbb89391b2c426532002bd0fbd34249c182257405271"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
